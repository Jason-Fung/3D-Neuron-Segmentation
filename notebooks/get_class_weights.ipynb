{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "sys.path.insert(1, '..')\n",
    "from processing.processing_functions import *\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "if use_cuda == True:\n",
    "    print(\"Using Cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset\n",
    "import tifffile\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "# yaml experiment file location\n",
    "project_path = os.path.abspath(os.path.abspath(os.path.dirname('__file__')) + \"/../\")\n",
    "exp_path = \"/config/convnets/ResUNet\"\n",
    "exp_file = \"/exp_1.yml\"\n",
    "\n",
    "with open(project_path + exp_path + exp_file, \"r\") as stream:\n",
    "    try:\n",
    "        config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "raw_path = \"/Users/jasonfung/haaslabdataimages@gmail.com - Google Drive/My Drive/Images/Raw/*.tif\"\n",
    "mask_path = \"/Users/jasonfung/haaslabdataimages@gmail.com - Google Drive/My Drive/Images/Mask/*.tif\"\n",
    "\n",
    "raw_filename_list = glob.glob(raw_path) \n",
    "mask_filename_list = glob.glob(mask_path)\n",
    "\n",
    "# Pre Shuffle\n",
    "raw_filename_list.sort()\n",
    "mask_filename_list.sort()\n",
    "\n",
    "# Shuffle the filename list\n",
    "from sklearn.utils import shuffle\n",
    "raw_filename_list, mask_filename_list = shuffle(raw_filename_list, mask_filename_list, random_state = 42)\n",
    "\n",
    "# define patching parameters\n",
    "lateral_steps = config['DATASET']['lateral_steps']\n",
    "axial_steps = config['DATASET']['axial_steps']\n",
    "patch_size = (axial_steps, lateral_steps, lateral_steps)\n",
    "split_size = config['DATASET']['split_size']\n",
    "\n",
    "raw_training_list, mask_training_list = raw_filename_list[:int(split_size*len(raw_filename_list))], mask_filename_list[:int(split_size*len(mask_filename_list))]\n",
    "raw_testing_list, mask_testing_list = raw_filename_list[int(split_size*len(raw_filename_list)):], mask_filename_list[int(split_size*len(mask_filename_list)):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([9.139044e+06, 9.353000e+03, 2.499600e+04, 1.647000e+03]), array([1.3322707e+07, 5.6730000e+03, 3.9245000e+04, 1.7190000e+03]), array([1.4408384e+07, 1.8920000e+03, 7.0510000e+03, 5.9300000e+02]), array([4.9726276e+07, 1.0850000e+04, 6.6928000e+04, 3.3060000e+03]), array([2.1720128e+07, 8.6580000e+03, 2.8316000e+04, 8.5000000e+02]), array([1.3094437e+07, 2.4280000e+03, 9.6620000e+03, 6.7300000e+02]), array([1.6921378e+07, 2.9145000e+04, 8.4869000e+04, 3.9680000e+03]), array([2.7999546e+07, 1.0398000e+04, 3.8658000e+04, 8.0600000e+02]), array([2.323913e+07, 1.255900e+04, 7.764100e+04, 1.486000e+03]), array([1.8059674e+07, 7.9160000e+03, 1.7935000e+04, 2.4110000e+03]), array([2.0134425e+07, 5.1590000e+03, 4.1832000e+04, 3.6720000e+03]), array([2.2252225e+07, 1.2728000e+04, 1.6971000e+04, 3.1600000e+02]), array([3.876191e+07, 7.543000e+03, 2.290400e+04, 4.955000e+03]), array([1.7023313e+07, 4.4340000e+03, 1.0615000e+04, 9.9800000e+02])]\n"
     ]
    }
   ],
   "source": [
    "def get_class_weights(mask_list, classes = 3):\n",
    "    # calculate balanced class weights\n",
    "    # mask_list: list()\n",
    "    # classes: integer num_class - 1\n",
    "\n",
    "\n",
    "    process_mask = process_masks(classes)\n",
    "    tot_mask_len = 0\n",
    "    mask_bin_count = []\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for mask_name in mask_list:\n",
    "        mask = tifffile.imread(mask_name).astype(np.float16)\n",
    "        mask = process_mask(mask)\n",
    "        mask_ind = le.fit_transform(mask.flatten())\n",
    "        mask_bin_count.append(np.bincount(mask_ind).astype(np.float64))\n",
    "        tot_mask_len += len(mask.flatten())\n",
    "\n",
    "    mask_bin_count = np.sum(np.array(mask_bin_count),axis = 0)\n",
    "    weights = tot_mask_len / (len(le.classes_) * mask_bin_count.astype(np.float64))\n",
    "    return weights\n",
    "    \n",
    "test_weights = get_class_weights(mask_training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.50526286e-01, 5.95106140e+02, 1.57112327e+02, 2.79604321e+03])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e948cd2eddc2b56aed0b51f92bfb3429aca2637a323db441b1bbdcb5065963e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
