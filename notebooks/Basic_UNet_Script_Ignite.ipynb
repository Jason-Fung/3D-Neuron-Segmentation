{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c5ce19",
   "metadata": {},
   "source": [
    "## Import Modules and Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e84821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T17:45:14.257979Z",
     "iopub.status.busy": "2022-08-11T17:45:14.257691Z",
     "iopub.status.idle": "2022-08-11T17:45:16.801678Z",
     "shell.execute_reply": "2022-08-11T17:45:16.797616Z",
     "shell.execute_reply.started": "2022-08-11T17:45:14.257905Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cf8960a299cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprocessing_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# import deep learning libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/neuron_segment/processing_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtifffile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/keras/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_layer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_layer_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/keras/engine/compile_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlosses_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/keras/metrics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Individual metric classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMeanRelativeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBinaryAccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/keras/metrics/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtensor_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mactivation_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Image preprocessing layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m from pandas.core.api import (\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;31m# dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mInt8Dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m from pandas.core.groupby import (\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mGrouper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/pandas/core/groupby/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.core.groupby.generic import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_series_with_explicit_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    127\u001b[0m )\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m from pandas.core import (\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0malgorithms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPandasObject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexingMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \"\"\"\n\u001b[1;32m    190\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0manalogue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mStore\u001b[0m \u001b[0mmulti\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mNDFrame\u001b[0;34m()\u001b[0m\n\u001b[1;32m   7436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7437\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7438\u001b[0;31m     def asfreq(\n\u001b[0m\u001b[1;32m   7439\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFrameOrSeries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7440\u001b[0m         \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(decorated)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mdocstring_components\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0mdocstring_components\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdedent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecorated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocstrings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/textwrap.py\u001b[0m in \u001b[0;36mdedent\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(?m)^'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import utility libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import pytz\n",
    "import random\n",
    "\n",
    "from processing_functions import *\n",
    "\n",
    "# import deep learning libraries\n",
    "from torchvision import transforms, utils\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import trange\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Metric, Loss\n",
    "import pprint\n",
    "\n",
    "\n",
    "# from monai.losses import DiceLoss\n",
    "from monai.losses import DiceLoss, FocalLoss, DiceFocalLoss, DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import BasicUNet, UNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    ")\n",
    "\n",
    "# import processing libraries\n",
    "from patchify import unpatchify\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a558ba",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.803081Z",
     "iopub.status.idle": "2022-08-11T17:45:16.803579Z",
     "shell.execute_reply": "2022-08-11T17:45:16.803332Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b90374",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.804921Z",
     "iopub.status.idle": "2022-08-11T17:45:16.805420Z",
     "shell.execute_reply": "2022-08-11T17:45:16.805163Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # cloud server\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# macbook\n",
    "# # use_mps = torch.has_mps\n",
    "# use_mps = False\n",
    "# device = torch.device(\"mps\" if use_mps else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff923902",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.806810Z",
     "iopub.status.idle": "2022-08-11T17:45:16.807308Z",
     "shell.execute_reply": "2022-08-11T17:45:16.807065Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bada83a",
   "metadata": {},
   "source": [
    "## Read TIF images into Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385cbd0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.808672Z",
     "iopub.status.idle": "2022-08-11T17:45:16.809174Z",
     "shell.execute_reply": "2022-08-11T17:45:16.808928Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import tifffile\n",
    "import glob\n",
    "\n",
    "# Cloud Server\n",
    "raw_path = \"/home/jovyan/workspace/Images/Raw/*.tif\"\n",
    "mask_path = \"/home/jovyan/workspace/Images/Mask/*.tif\"\n",
    "\n",
    "# # Jason's Desktop\n",
    "# raw_path = \"I:\\My Drive\\Raw\\*.tif\"\n",
    "# mask_path = \"I:\\My Drive\\Mask\\*.tif\"\n",
    "\n",
    "# # Jason's Macbook\n",
    "# raw_path = \"/Users/jasonfung/haaslabdataimages@gmail.com - Google Drive/My Drive/Raw/*.tif\"\n",
    "# mask_path = \"/Users/jasonfung/haaslabdataimages@gmail.com - Google Drive/My Drive/Mask/*.tif\"\n",
    "\n",
    "raw_filename_list = glob.glob(raw_path) \n",
    "mask_filename_list = glob.glob(mask_path)\n",
    "\n",
    "# Pre Shuffle\n",
    "raw_filename_list.sort()\n",
    "mask_filename_list.sort()\n",
    "\n",
    "# Shuffle the filename list\n",
    "from sklearn.utils import shuffle\n",
    "raw_filename_list, mask_filename_list = shuffle(raw_filename_list, mask_filename_list, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b111d457",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.810950Z",
     "iopub.status.idle": "2022-08-11T17:45:16.811444Z",
     "shell.execute_reply": "2022-08-11T17:45:16.811201Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec497891",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.812886Z",
     "iopub.status.idle": "2022-08-11T17:45:16.813388Z",
     "shell.execute_reply": "2022-08-11T17:45:16.813140Z"
    }
   },
   "outputs": [],
   "source": [
    "len(raw_filename_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab2a227",
   "metadata": {},
   "source": [
    "## Processing Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac884ec",
   "metadata": {},
   "source": [
    "## Patching and Reconstruction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0ccc61",
   "metadata": {},
   "source": [
    "Input of an image is (# z stacks, # x pixels, # y pixels). Then it is split into sub volumes of size (z patch size, x patch size, y patch size) where each subvolume is (voxelized), meaning it has a coordinate relative to the original image. This ends up becoming a (z location, x location, y location, z patch size, x patch size, y patch size).\n",
    "\n",
    "If the image has a depth that cannot be evenly split by 2^n depth patch size where n is an integer, the function patch_images() will return an \"upper half\" and a \"lower half\" of the image. For example, given an image size of (77,512,512) and a z patch size of 16, x patch size of 32, and y patch of 32, the image cannot be evenly split into 16ths, since 77 % 16 = 4 remainder 13. Therefore, starting from the top of the stack to slice 64: the upper half becomes (64, 512, 512). Contrastly, starting from the bottom of the stack at slice 77 to slice 61, the lower half becomes (16, 512, 512). The two split volumes will become merged in the end.\n",
    "\n",
    "To prepare for training, the coordinated subvolumes are reshaped into \"batch form\". From the previous example with the upper half (64, 512, 512) split and coordinated into a 6D array (4, 16, 16, 16, 32, 32) -> (4 * 16 * 16, 16, 32, 32).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505edf0",
   "metadata": {},
   "source": [
    "## Split Training and Testing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57a3fe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.814737Z",
     "iopub.status.idle": "2022-08-11T17:45:16.815236Z",
     "shell.execute_reply": "2022-08-11T17:45:16.814991Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define patching parameters\n",
    "lateral_steps = 64\n",
    "axial_steps = 16\n",
    "patch_size = (axial_steps, lateral_steps, lateral_steps)\n",
    "split_size = 0.8\n",
    "dim_order = (0,4,1,2,3) # define the image and mask dimension order\n",
    "\n",
    "patch_transform = transforms.Compose([\n",
    "#                                       new_shape(new_xy = (600,960)),\n",
    "                                      MinMaxScalerVectorized(),\n",
    "                                      patch_imgs(xy_step = lateral_steps, z_step = axial_steps, patch_size = patch_size, is_mask = False)])\n",
    "\n",
    "# define transforms for labeled masks\n",
    "label_transforms = transforms.Compose([\n",
    "#                                        new_shape(new_xy = (600,960)),\n",
    "                                       process_masks(int_class = 3),\n",
    "                                       patch_imgs(xy_step = lateral_steps, z_step = axial_steps, patch_size = patch_size, is_mask = True)])\n",
    "\n",
    "\n",
    "raw_training_list, mask_training_list = raw_filename_list[:int(split_size*len(raw_filename_list))], mask_filename_list[:int(split_size*len(mask_filename_list))]\n",
    "raw_testing_list, mask_testing_list = raw_filename_list[int(split_size*len(raw_filename_list)):], mask_filename_list[int(split_size*len(mask_filename_list)):]\n",
    "print(len(raw_training_list))\n",
    "\n",
    "training_data = MyImageDataset(raw_training_list,\n",
    "                               mask_training_list,\n",
    "                               transform = patch_transform,\n",
    "                               label_transform = label_transforms,\n",
    "                               device = device,\n",
    "                               img_order = dim_order,\n",
    "                               mask_order = dim_order,\n",
    "                               num_classes = 4,\n",
    "                               train=True)\n",
    "\n",
    "testing_data = MyImageDataset(raw_testing_list,\n",
    "                              mask_testing_list,\n",
    "                              transform = patch_transform,\n",
    "                              label_transform = label_transforms,\n",
    "                              device = device,\n",
    "                              img_order = dim_order,\n",
    "                              mask_order = dim_order,\n",
    "                              num_classes = 4,\n",
    "                              train=False)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "training_dataloader = DataLoader(training_data, batch_size = 1, shuffle = False)\n",
    "testing_dataloader = DataLoader(testing_data, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5bc2e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.816794Z",
     "iopub.status.idle": "2022-08-11T17:45:16.817292Z",
     "shell.execute_reply": "2022-08-11T17:45:16.817045Z"
    }
   },
   "outputs": [],
   "source": [
    "upper, upper_shape, lower, lower_shape, full_mask, mask_upper, mask_lower = next(iter(training_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75f994",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.818719Z",
     "iopub.status.idle": "2022-08-11T17:45:16.819221Z",
     "shell.execute_reply": "2022-08-11T17:45:16.818974Z"
    }
   },
   "outputs": [],
   "source": [
    "len(upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2adea31",
   "metadata": {},
   "source": [
    "# Define Model and Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eb5419",
   "metadata": {},
   "source": [
    "### Model: UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e580ab7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.820465Z",
     "iopub.status.idle": "2022-08-11T17:45:16.820959Z",
     "shell.execute_reply": "2022-08-11T17:45:16.820720Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up loss and optimizer\n",
    "max_epochs = 150\n",
    "dropout = 0.15\n",
    "learning_rate = 5e-5\n",
    "# decay = 1e-5\n",
    "input_chnl = 1\n",
    "output_chnl = 4\n",
    "\n",
    "model = BasicUNet(spatial_dims=3, \n",
    "                  in_channels = input_chnl,\n",
    "                  out_channels = output_chnl,\n",
    "                  features = (16, 32, 64, 128, 256, 16),\n",
    "                  norm = \"batch\",\n",
    "                  dropout = dropout,\n",
    "               )\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df6469",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.822378Z",
     "iopub.status.idle": "2022-08-11T17:45:16.822949Z",
     "shell.execute_reply": "2022-08-11T17:45:16.822641Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d337dbe1",
   "metadata": {},
   "source": [
    "## Loss, Metric, Schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc968519",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.824544Z",
     "iopub.status.idle": "2022-08-11T17:45:16.825052Z",
     "shell.execute_reply": "2022-08-11T17:45:16.824793Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss_function = FocalLoss()\n",
    "loss_function = DiceCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_epochs/20, verbose = True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, threshold=1e-3, verbose=True)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "# Instantiate Dice metric\n",
    "dice = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans = True)\n",
    "discretize = Compose([Activations(softmax = True), \n",
    "                      AsDiscrete(logit_thresh=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c14d1",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb20448",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.826181Z",
     "iopub.status.idle": "2022-08-11T17:45:16.826731Z",
     "shell.execute_reply": "2022-08-11T17:45:16.826434Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Augmentation Function parameters\n",
    "# degree = (25, 5, 5)\n",
    "# translate = (10,10,10)\n",
    "# transform_rotate = torchio.RandomAffine(degrees=degree, \n",
    "#                                         translation=translate, \n",
    "#                                         image_interpolation=\"bspline\")\n",
    "\n",
    "# transform_flip = torchio.RandomFlip(axes=('ap',))\n",
    "# all_transform = torchio.Compose([transform_rotate,\n",
    "#                                  transform_flip])\n",
    "\n",
    "# Augmentation Function parameters using resnet parameters\n",
    "degree = (25, 0, 0)\n",
    "# translate = (10,10,10)\n",
    "transform_rotate = torchio.RandomAffine(degrees=degree, \n",
    "#                                         translation=translate, \n",
    "                                        image_interpolation=\"bspline\")\n",
    "transform_flip = torchio.RandomFlip(axes=('ap',))\n",
    "all_transform = torchio.Compose([transform_rotate,\n",
    "                                 transform_flip])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284e8074",
   "metadata": {},
   "source": [
    "## Define Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d47910",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.828346Z",
     "iopub.status.idle": "2022-08-11T17:45:16.828866Z",
     "shell.execute_reply": "2022-08-11T17:45:16.828605Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(engine, batch):\n",
    "\n",
    "    batch_size = 64\n",
    "    lateral_steps = 64\n",
    "    axial_steps = 16\n",
    "    patch_size = (axial_steps, lateral_steps, lateral_steps)    \n",
    "    augment = True\n",
    "    shuffle = True\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    count_loss = 0\n",
    "    # Instantiate the dice sum for each class\n",
    "    \n",
    "    upper_img, upper_shape, lower_img, lower_shape, full_mask, upper_mask, lower_mask = batch\n",
    "    # upper_img: dict() of {\"index 1\": upper_raw_tensor_1, \"index 2\": upper_raw_tensor_2, ..., \"index n\": upper_raw_tensor_n} raw_tensor = FloatTensor(Z,Y,X)\n",
    "    # lower_img: dict() of {\"index 1\": lower_raw_tensor_1, \"index 2\": lower_raw_tensor_2\", ..., \"index n\": lower_raw_tensor_n} raw_tensor = FloatTensor(Z,Y,X)\n",
    "    # upper_shape: tuple() representing shape of the upper volume (z,y,x) Note: this is used for reconstruction\n",
    "    # lower_shape: tuple() representing shape of the lower volume (z,y,x) Note: this is used for reconstruction\n",
    "    # full_mask: torch.FloatTensor of size (B,C,Z,Y,X) B = batch, C = Class Channel \n",
    "    # upper_mask: dict() of {\"index 1\": upper_mask_tensor_1, \"index 2\": upper_mask_tensor_2, ..., \"index n\": upper_mask_tensor_n} mask_tensor = FloatTensor(C,Z,Y,X)\n",
    "    # lower_mask: dict() of {\"index 1\": upper_mask_tensor_1, \"index 2\": upper_mask_tensor_2, ..., \"index n\": lower_mask_tensor_n} mask_tensor = FloatTensor(C,Z,Y,X)\n",
    "    # Empty list to place subvolumes in\n",
    "    \n",
    "    tmp_upper_dict = {}\n",
    "    tmp_lower_dict = {}    \n",
    "    \n",
    "    if shuffle == True:\n",
    "        # shuffle the batches\n",
    "        upper_key_list = list(range(len(upper_img)))\n",
    "        random.shuffle(upper_key_list)\n",
    "        \n",
    "        # check if lower img exists, otherwise perform shuffling\n",
    "        if lower_img == None:\n",
    "            pass\n",
    "        else:\n",
    "            lower_key_list = list(range(len(lower_img)))\n",
    "            random.shuffle(upper_key_list)\n",
    "    else:\n",
    "        upper_key_list = list(range(len(upper_img)))\n",
    "        lower_key_list = list(range(len(lower_img)))\n",
    "    \n",
    "    \n",
    "    # Only train on evenly split images\n",
    "    if lower_img == None:\n",
    "        num_subvolumes = len(upper_img)\n",
    "        for bindex in trange(0, num_subvolumes, batch_size):\n",
    "            if bindex + batch_size > num_subvolumes:\n",
    "                # if the bindex surpasses the number of number of sub volumes\n",
    "                batch_keys = upper_key_list[bindex:num_subvolumes]\n",
    "            else:\n",
    "                batch_keys = upper_key_list[bindex:bindex+batch_size]\n",
    "            \n",
    "            sub_imgs = torch.squeeze(torch.stack([upper_img.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "            sub_masks = torch.squeeze(torch.stack([upper_mask.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(sub_imgs)\n",
    "            probabilities = torch.softmax(output, 1)\n",
    "            \n",
    "            # discretize probability values \n",
    "            prediction = torch.argmax(probabilities, 1)\n",
    "            tmp_upper_dict.update(dict(zip(batch_keys,prediction)))\n",
    "            \n",
    "            # calculate the loss for the current batch, save the loss per epoch to calculate the average running loss\n",
    "            current_loss = loss_function(probabilities, sub_masks) # + dice_loss(predictions, patch_gt)\n",
    "            current_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += current_loss.item()\n",
    "        \n",
    "        # lower list does not exist\n",
    "        tmp_lower_list = None\n",
    "            \n",
    "    # train on both \n",
    "    else:\n",
    "        num_upper_subvolumes = len(upper_img)\n",
    "        if augment:\n",
    "            # Extract index of non-zero subvolumes\n",
    "            upper_indexes = get_index_nonempty_cubes(upper_mask)\n",
    "            \n",
    "            # Augment on non-zero subvolumes based on their location in the volume (by index)\n",
    "            for bindex in range(0, len(upper_indexes), batch_size):\n",
    "                # for augmentation\n",
    "                if bindex + batch_size > len(upper_indexes):\n",
    "                    upper_batch = upper_indexes[bindex:len(upper_indexes)]\n",
    "                else:\n",
    "                    upper_batch = upper_indexes[bindex:bindex+batch_size]\n",
    "                    \n",
    "                sub_imgs, sub_masks = augmentation(all_transform, upper_img, upper_mask, upper_batch)\n",
    "                sub_imgs, sub_masks = sub_imgs.to(device), sub_masks.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(sub_imgs)\n",
    "                probabilities = torch.softmax(output, 1)\n",
    "                prediction = torch.argmax(probabilities, 1)\n",
    "                \n",
    "                current_loss = loss_function(probabilities, sub_masks)\n",
    "                current_loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += current_loss.item()\n",
    "                count_loss += 1\n",
    "        \n",
    "        for bindex in range(0, num_upper_subvolumes, batch_size):\n",
    "            if bindex + batch_size > num_upper_subvolumes:\n",
    "                # if the bindex surpasses the number of number of sub volumes\n",
    "                batch_keys = upper_key_list[bindex:num_upper_subvolumes]\n",
    "            else:\n",
    "                batch_keys = upper_key_list[bindex:bindex+batch_size]\n",
    "            \n",
    "            sub_imgs = torch.squeeze(torch.stack([upper_img.get(key) for key in batch_keys], dim=1), dim = 0) \n",
    "            sub_masks = torch.squeeze(torch.stack([upper_mask.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(sub_imgs) # predict the batches\n",
    "            probabilities = torch.softmax(output, 1) \n",
    "            prediction = torch.argmax(probabilities,1)\n",
    "            \n",
    "            # update the upper img dictionary\n",
    "            tmp_upper_dict.update(dict(zip(batch_keys,prediction)))\n",
    "            \n",
    "            current_loss = loss_function(probabilities, sub_masks) # + dice_loss(predictions, patch_gt)\n",
    "            \n",
    "            current_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += current_loss.item()\n",
    "            count_loss += 1\n",
    "        \n",
    "        num_lower_subvolumes = len(lower_img)\n",
    "        if augment:\n",
    "            \n",
    "            lower_indexes = get_index_nonempty_cubes(lower_mask)\n",
    "            \n",
    "            for bindex in range(0, len(lower_indexes), batch_size):\n",
    "                # for augmentation\n",
    "                if bindex + batch_size > len(lower_indexes):\n",
    "                    lower_batch = lower_indexes[bindex:len(lower_indexes)]\n",
    "                else:\n",
    "                    lower_batch = lower_indexes[bindex:bindex+batch_size]\n",
    "                    \n",
    "                sub_imgs, sub_masks = augmentation(all_transform, lower_img, lower_mask, lower_batch)\n",
    "                sub_imgs, sub_masks = sub_imgs.to(device), sub_masks.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(sub_imgs)\n",
    "                probabilities = torch.softmax(output, 1)\n",
    "                prediction = torch.argmax(probabilities, 1)\n",
    "                \n",
    "                current_loss = loss_function(probabilities, sub_masks)\n",
    "                current_loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += current_loss.item()\n",
    "                count_loss += 1\n",
    "                \n",
    "        for bindex in range(0, num_lower_subvolumes, batch_size):\n",
    "            if bindex + batch_size > num_lower_subvolumes:\n",
    "                # if the bindex surpasses the number of number of sub volumes\n",
    "                batch_keys = lower_key_list[bindex:num_lower_subvolumes]\n",
    "            else:\n",
    "                batch_keys = lower_key_list[bindex:bindex+batch_size]\n",
    "            \n",
    "            sub_imgs = torch.squeeze(torch.stack([lower_img.get(key) for key in batch_keys], dim=1), dim = 0) \n",
    "            sub_masks = torch.squeeze(torch.stack([lower_mask.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(sub_imgs)\n",
    "            probabilities = torch.softmax(output, 1)\n",
    "            prediction = torch.argmax(probabilities,1)\n",
    "            \n",
    "            # update the lower dictionary\n",
    "            tmp_lower_dict.update(dict(zip(batch_keys,prediction)))\n",
    "\n",
    "            current_loss = loss_function(probabilities, sub_masks) # + dice_loss(predictions, patch_gt)\n",
    "            current_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += current_loss.item()\n",
    "            count_loss += 1\n",
    "\n",
    "        orig_shape = full_mask.shape[1:]\n",
    "        reconstructed_mask_order = (3,0,1,2)\n",
    "\n",
    "\n",
    "        upper_values = torch.stack([tmp_upper_dict[key] for key in list(range(len(tmp_upper_dict)))])\n",
    "        lower_values = torch.stack([tmp_lower_dict[key] for key in list(range(len(tmp_lower_dict)))])\n",
    "\n",
    "\n",
    "        reconstructed = reconstruct_training_masks(upper_values, lower_values, upper_shape, \n",
    "                                                   lower_shape, patch_size, orig_shape) # returns (z,y,x)\n",
    "        reconstructed = to_categorical_torch(reconstructed, num_classes = 4) # returns (z,y,x,c)\n",
    "        reconstructed = reconstructed.type(torch.int16)\n",
    "        reconstructed = torch.permute(reconstructed, reconstructed_mask_order)\n",
    "        reconstructed = torch.unsqueeze(reconstructed, 0) # make reconstructed image into (Batch,c,z,y,x)\n",
    "\n",
    "        full_mask = full_mask.type(torch.int16)\n",
    "        # gt_mask = torch.permute(full_mask, dim_order).cpu() # roll axis of grount truth mask into (batch,c,z,y,x)\n",
    "        \n",
    "    return {\"batch_loss\":running_loss/count_loss, \"y_pred\":reconstructed, \"y\":full_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1135b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.830657Z",
     "iopub.status.idle": "2022-08-11T17:45:16.831231Z",
     "shell.execute_reply": "2022-08-11T17:45:16.830964Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(engine, batch):\n",
    "    \n",
    "    batch_size = 64\n",
    "    axial_steps = 16\n",
    "    patch_size = (axial_steps, lateral_steps, lateral_steps)\n",
    "    shuffle = False\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0\n",
    "        count_loss = 0\n",
    "\n",
    "        upper_img, upper_shape, lower_img, lower_shape, full_mask, upper_mask, lower_mask = batch\n",
    "        # Empty list to place subvolumes in\n",
    "        tmp_upper_dict = {}\n",
    "        tmp_lower_dict = {}\n",
    "        \n",
    "        \n",
    "        upper_key_list = list(range(len(upper_img)))\n",
    "        lower_key_list = list(range(len(lower_img)))\n",
    "\n",
    "        # Only train on evenly split images\n",
    "        if lower_img == None:\n",
    "            num_subvolumes = len(upper_img)\n",
    "            for bindex in range(0, num_subvolumes, batch_size):\n",
    "                if bindex + batch_size > num_subvolumes:\n",
    "                    # if the bindex surpasses the number of number of sub volumes\n",
    "                    batch_keys = upper_key_list[bindex:num_subvolumes]\n",
    "                else:\n",
    "                    batch_keys = upper_key_list[bindex:bindex+batch_size]\n",
    "                \n",
    "                sub_imgs = torch.squeeze(torch.stack([upper_img.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "                sub_masks = torch.squeeze(torch.stack([upper_mask.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = model(sub_imgs)\n",
    "                probabilities = torch.softmax(output, 1)\n",
    "\n",
    "                # discretize probability values \n",
    "                prediction = torch.argmax(probabilities, 1)\n",
    "                tmp_upper_dict.update(dict(zip(batch_keys,prediction)))\n",
    "\n",
    "                # calculate the loss for the current batch, save the loss per epoch to calculate the average running loss\n",
    "                current_loss = loss_function(probabilities, sub_masks) # + dice_loss(predictions, patch_gt)\n",
    "                running_loss += current_loss.item()\n",
    "                count_loss += 1\n",
    "\n",
    "            # lower list does not exist\n",
    "            tmp_lower_list = None\n",
    "\n",
    "        # train on both \n",
    "        else:\n",
    "            num_subvolumes = len(upper_img)\n",
    "            for bindex in range(0, num_subvolumes, batch_size):\n",
    "                if bindex + batch_size > num_subvolumes:\n",
    "                    # if the bindex surpasses the number of number of sub volumes\n",
    "                    batch_keys = upper_key_list[bindex:num_subvolumes]\n",
    "                else:\n",
    "                    batch_keys = upper_key_list[bindex:bindex+batch_size]\n",
    "                \n",
    "                sub_imgs = torch.squeeze(torch.stack([upper_img.get(key) for key in batch_keys], dim=1), dim = 0) \n",
    "                sub_masks = torch.squeeze(torch.stack([upper_mask.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(sub_imgs) # predict the batches\n",
    "                probabilities = torch.softmax(output, 1) \n",
    "                prediction = torch.argmax(probabilities,1)\n",
    "\n",
    "                current_loss = loss_function(probabilities, sub_masks) # + dice_loss(predictions, patch_gt)\n",
    "                running_loss += current_loss.item()\n",
    "                count_loss += 1\n",
    "\n",
    "                # update the upper img dictionary\n",
    "                tmp_upper_dict.update(dict(zip(batch_keys,prediction)))\n",
    "\n",
    "            num_subvolumes = len(lower_img)\n",
    "            for bindex in range(0, num_subvolumes, batch_size):\n",
    "                if bindex + batch_size > num_subvolumes:\n",
    "                    # if the bindex surpasses the number of number of sub volumes\n",
    "                    batch_keys = lower_key_list[bindex:num_subvolumes]\n",
    "                else:\n",
    "                    batch_keys = lower_key_list[bindex:bindex+batch_size]\n",
    "                \n",
    "                sub_imgs = torch.squeeze(torch.stack([lower_img.get(key) for key in batch_keys], dim=1), dim = 0) \n",
    "                sub_masks = torch.squeeze(torch.stack([lower_mask.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "\n",
    "                output = model(sub_imgs)\n",
    "                probabilities = torch.softmax(output, 1)\n",
    "                prediction = torch.argmax(probabilities,1)\n",
    "                current_loss = loss_function(probabilities, sub_masks) # + dice_loss(predictions, patch_gt)\n",
    "                running_loss += current_loss.item()\n",
    "                count_loss += 1\n",
    "\n",
    "                # update the lower dictionary\n",
    "                tmp_lower_dict.update(dict(zip(batch_keys,prediction)))\n",
    "\n",
    "            # return tmp_upper_list, tmp_lower_list, running_loss / count\n",
    "    \n",
    "        # neuron reconstruction to calculate the dice metric.\n",
    "        orig_shape = full_mask.shape[1:]\n",
    "        # print(full_mask.shape)\n",
    "        reconstructed_mask_order = (3,0,1,2)\n",
    "\n",
    "\n",
    "        upper_values = torch.stack([tmp_upper_dict[key] for key in list(range(len(tmp_upper_dict)))])\n",
    "        lower_values = torch.stack([tmp_lower_dict[key] for key in list(range(len(tmp_lower_dict)))])\n",
    "\n",
    "\n",
    "        reconstructed = reconstruct_training_masks(upper_values, lower_values, upper_shape, \n",
    "                                                    lower_shape, patch_size, orig_shape) # returns (z,y,x)\n",
    "        reconstructed = to_categorical_torch(reconstructed, num_classes = 4) # returns (z,y,x,c)\n",
    "        reconstructed = reconstructed.type(torch.int16)\n",
    "        reconstructed = torch.permute(reconstructed, reconstructed_mask_order)\n",
    "        reconstructed = torch.unsqueeze(reconstructed, 0) # make reconstructed image into (Batch,c,z,y,x)\n",
    "\n",
    "        full_mask = full_mask.type(torch.int16)\n",
    "        # gt_mask = torch.permute(full_mask, dim_order).cpu() # roll axis of grount truth mask into (batch,c,z,y,x)\n",
    "        \n",
    "    return {\"batch_loss\":running_loss/count_loss, \"y_pred\":reconstructed, \"y\":full_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c833f30",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.832504Z",
     "iopub.status.idle": "2022-08-11T17:45:16.833033Z",
     "shell.execute_reply": "2022-08-11T17:45:16.832767Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Engine(train)\n",
    "evaluator = Engine(validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89273a31",
   "metadata": {},
   "source": [
    "## Metrics and Progress Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce6d809",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.834666Z",
     "iopub.status.idle": "2022-08-11T17:45:16.835211Z",
     "shell.execute_reply": "2022-08-11T17:45:16.834954Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up progress bar\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.metrics import RunningAverage\n",
    "from ignite.metrics import ConfusionMatrix, DiceCoefficient\n",
    "\n",
    "def metric_output_transform(output):\n",
    "    y_pred, y = output[\"y_pred\"], output[\"y\"]\n",
    "    return y_pred, y\n",
    "\n",
    "cm = ConfusionMatrix(num_classes=4, output_transform = metric_output_transform)\n",
    "dice_metric = RunningAverage(DiceCoefficient(cm))\n",
    "\n",
    "# progress output transform\n",
    "def loss_output_transform(output):\n",
    "    loss = output[\"batch_loss\"]\n",
    "    return loss\n",
    "\n",
    "# Attach both metric to trainer and evaluator engine\n",
    "dice_metric.attach(trainer, \"Dice\")\n",
    "dice_metric.attach(evaluator, \"Dice\")\n",
    "\n",
    "# RunningAverage(output_transform=loss_output_transform).attach(trainer, \"batch_loss\")\n",
    "RunningAverage(output_transform=loss_output_transform).attach(evaluator, \"batch_loss\")\n",
    "pbar = ProgressBar(persist=True)\n",
    "pbar.attach(trainer, metric_names=[\"batch_loss\"])\n",
    "pbar.attach(evaluator, metric_names=[\"batch_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03637fc",
   "metadata": {},
   "source": [
    "## Setup Model and Log Saving Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf4d46",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.837407Z",
     "iopub.status.idle": "2022-08-11T17:45:16.837947Z",
     "shell.execute_reply": "2022-08-11T17:45:16.837697Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"BasicUNET\"\n",
    "date = datetime.now(tz=pytz.utc).strftime('%Y%m%d')\n",
    "time = datetime.now(tz=pytz.utc).strftime('%H%M%S')\n",
    "\n",
    "model_directory = f\"/home/jovyan/workspace/results/{model_name}/\"\n",
    "date_directory = f\"/{date}/\"\n",
    "time_directory = f\"{date}_{time}/\"\n",
    "log_directory = model_directory + date_directory + time_directory + \"log\"\n",
    "os.makedirs(log_directory)\n",
    "\n",
    "# create writer to log results into tensorboard\n",
    "log_writer = SummaryWriter(log_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f7657",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.839481Z",
     "iopub.status.idle": "2022-08-11T17:45:16.840011Z",
     "shell.execute_reply": "2022-08-11T17:45:16.839745Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "@trainer.on(Events.STARTED)\n",
    "def print_start(trainer):\n",
    "    print(\"Training Started\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_STARTED)\n",
    "def print_epoch(trainer):\n",
    "    print(\"Epoch : {}\".format(trainer.state.epoch))\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def save_model(trainer):\n",
    "    global best_dice\n",
    "    global best_epoch\n",
    "    global best_epoch_file\n",
    "    global best_loss\n",
    "    \n",
    "    epoch = trainer.state.epoch\n",
    "    def get_saved_model_path(epoch):\n",
    "        return model_directory + date_directory + time_directory + f\"{model_name}_{epoch}.pth\"\n",
    "\n",
    "    # initialize global values\n",
    "    best_dice = -torch.inf if epoch == 1 else best_dice\n",
    "    best_loss = torch.inf if epoch == 1 else best_loss\n",
    "    best_epoch = 1 if epoch == 1 else best_epoch\n",
    "    best_epoch_file = '' if epoch == 1 else best_epoch_file\n",
    "    \n",
    "    def log_training_results(trainer):\n",
    "        evaluator.run(training_dataloader)\n",
    "        # Get engine metrics and losses\n",
    "        training_metrics = copy.deepcopy(evaluator.state.metrics)\n",
    "        pbar.log_message(\n",
    "            \"Training Results - Epoch: {} \\nMetrics\\n{}\"\n",
    "            .format(trainer.state.epoch, pprint.pformat(training_metrics)))\n",
    "        return training_metrics\n",
    "    \n",
    "    def log_testing_results(trainer):\n",
    "        evaluator.run(testing_dataloader)\n",
    "        testing_metrics = copy.deepcopy(evaluator.state.metrics)\n",
    "#         scheduler.step(testing_metrics[\"batch_loss\"])\n",
    "        scheduler.step()\n",
    "        pbar.log_message(\n",
    "            \"Validation Results - Epoch: {} \\nMetrics\\n{}\"\n",
    "            .format(trainer.state.epoch, pprint.pformat(testing_metrics)))\n",
    "        return testing_metrics\n",
    "    \n",
    "    training_metrics= log_training_results(trainer)\n",
    "    testing_metrics= log_testing_results(trainer)\n",
    "    \n",
    "    train_dice = training_metrics['Dice']\n",
    "    val_dice = testing_metrics['Dice']\n",
    "\n",
    "    train_mean_dice = torch.mean(train_dice)\n",
    "    val_mean_dice = torch.mean(val_dice)\n",
    "    train_loss = training_metrics['batch_loss']\n",
    "    val_loss = testing_metrics['batch_loss']\n",
    "    \n",
    "\n",
    "    # log results\n",
    "    log_writer.add_scalars('Training vs. Validation Loss',\n",
    "                       {'Training' : train_loss, 'Validation' : val_loss}, epoch)\n",
    "    log_writer.add_scalars('Training vs. Validation Mean Dice ',\n",
    "                       {'Training Mean Dice' : train_mean_dice, 'Validation Mean Dice' : val_mean_dice}, epoch)\n",
    "    log_writer.add_scalars('Training vs. Validation Soma Dice ',\n",
    "                       {'Training Soma Dice' : train_dice[1], 'Validation Soma Dice' : val_dice[1]}, epoch)\n",
    "    log_writer.add_scalars('Training vs. Validation Dendrite Dice ',\n",
    "                       {'Training Dendrite Dice' : train_dice[2], 'Validation Dendrite Dice' : val_dice[2]}, epoch)\n",
    "    log_writer.add_scalars('Training vs. Validation Filopodias Dice ',\n",
    "                       {'Training Filopodias Dice' : train_dice[3], 'Validation Filopodias Dice' : val_dice[3]}, epoch)\n",
    "    log_writer.flush()\n",
    "\n",
    "    if (testing_metrics['batch_loss'] < best_loss):\n",
    "        \n",
    "        # if there was a previous model saved, delete that one\n",
    "        prev_best_epoch_file = get_saved_model_path(best_epoch)\n",
    "        if os.path.exists(prev_best_epoch_file):\n",
    "            os.remove(prev_best_epoch_file)\n",
    "\n",
    "        # update the best mean dice and loss and save the new model state\n",
    "#         best_dice = val_mean_dice\n",
    "        best_loss = testing_metrics['batch_loss']\n",
    "        best_epoch = epoch\n",
    "        best_epoch_file = get_saved_model_path(best_epoch)\n",
    "#         print(f'\\nEpoch: {best_epoch} - New best Dice and Loss! Mean Dice: {best_dice} Loss: {best_loss}\\n\\n\\n')\n",
    "        print(f'\\nEpoch: {best_epoch} - New best Loss! Loss: {best_loss}\\n\\n\\n')\n",
    "        torch.save(model.state_dict(), best_epoch_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee1c814",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f63f1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.841253Z",
     "iopub.status.idle": "2022-08-11T17:45:16.841695Z",
     "shell.execute_reply": "2022-08-11T17:45:16.841484Z"
    }
   },
   "outputs": [],
   "source": [
    "from ignite.handlers import EarlyStopping\n",
    "\n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['batch_loss']\n",
    "    return -val_loss\n",
    "\n",
    "handler = EarlyStopping(patience=10, score_function=score_function, min_delta=1e-6, trainer=trainer)\n",
    "evaluator.add_event_handler(Events.COMPLETED, handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4bedca",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-11T17:45:16.842591Z",
     "iopub.status.idle": "2022-08-11T17:45:16.843006Z",
     "shell.execute_reply": "2022-08-11T17:45:16.842819Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.run(training_dataloader, max_epochs = max_epochs)# Running Training Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b0f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e948cd2eddc2b56aed0b51f92bfb3429aca2637a323db441b1bbdcb5065963e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
