{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "219919d9",
   "metadata": {},
   "source": [
    "## Inferencing Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f678db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import core libaries\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import tifffile\n",
    "\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath(__vsc_ipynb_file__))\n",
    "sys.path.append(os.path.dirname(SCRIPT_DIR))\n",
    "from src.processing.processing_functions import *\n",
    "\n",
    "# get working directory\n",
    "path = os.getcwd()\n",
    "sys.path.append(path)\n",
    "\n",
    "# import machine learning libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from monai.inferers.inferer import SlidingWindowInferer, SliceInferer\n",
    "from monai.networks.nets import BasicUNet, UNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55de52bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize cuda if available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e859310d",
   "metadata": {},
   "source": [
    "## Using MONAI Sliding Window Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f7aad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = \"+s_+d_-f\"\n",
    "model_soma_dendrite = \"2D_Soma+Dendrite.pth\"\n",
    "yaml_filename = \"20230216_225012_ResUNet_experiment.yml\"\n",
    "parent_folder = \"C:\\\\Users\\\\Fungj\\\\Google Drive\\\\Masters Project\\\\Segmentation-Model\\\\3D-Neuron-Segment\\\\results\\\\ResUNET\\\\20230216\\\\1_512_512_+s_+d_-f\" # windows\n",
    "# parent_folder = \"/Users/jasonfung/Google Drive/Masters Project/Segmentation-Model/3D-Neuron-Segment/results/ResUNET/20230113/+s_+d_-f\" # mac\n",
    "yaml_file = f\"{parent_folder}/{yaml_filename}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4bc3a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATASET': {'AUGMENTATION': {'augment': True, 'gamma_lower': -0.5, 'gamma_upper': 0.6, 'mean_noise': 0.05, 'std_noise': 0.025, 'x_deg': 0, 'y_deg': 0, 'z_deg': 25}, 'artifacts': [7], 'axial_steps': 1, 'batch_size': 32, 'ex_autofluorescence': False, 'ex_melanocytes': True, 'exp': '+s_+d_-f', 'folds': 4, 'lateral_steps': 512, 'remove_artifacts': False, 'x_patch': 512, 'y_patch': 512, 'z_patch': 1}, 'MODEL': {'channel_layers': [64, 128, 256, 512, 1024], 'dropout': 0.15, 'input_dim': 1, 'l2': 0.00421, 'learning_rate': 7.54e-05, 'model_arch': 'UNET', 'norm': 'batch', 'num_res_units': 2, 'spatial_dim': 2, 'strides': [2, 2, 2, 2]}, 'RESULTS': {'log_file_path': '/home/jsfung/projects/def-haas/jsfung/results/ResUNet/20230216/1_512_512_+s_+d_-f/225012_log_fold_3', 'model_states_path': '/home/jsfung/projects/def-haas/jsfung/results/ResUNet/20230216/1_512_512_+s_+d_-f/+s_+d_-f_2D_ResUNet_3_141.pth'}, 'TRAINING': {'shuffle': True}, 'date': 'now', 'end_cycle': 20, 'loss': 'dice_ce', 'mask_path': '/home/jsfung/projects/def-haas/jsfung/Images/new_labels/Mask/*.tif', 'max_epochs': 200, 'model_name': 'ResUNet', 'parent_dir': '/home/haas/projects/def-haas/jsfung', 'raw_path': '/home/jsfung/projects/def-haas/jsfung/Images/new_labels/Raw/*.tif', 'weights': None}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "with open(yaml_file) as f:\n",
    "    config = yaml.load(f, Loader=SafeLoader)\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c6d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec74e689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from list\n",
      "Reading Mask from list\n"
     ]
    }
   ],
   "source": [
    "# pick test image\n",
    "raw_path = filedialog.askopenfilename()\n",
    "raw_img = glob.glob(raw_path)\n",
    "\n",
    "mask_path = filedialog.askopenfilename()\n",
    "mask_img = glob.glob(mask_path)\n",
    "# raw_img = ['E:\\\\Image_Folder\\\\SLAP2_Images\\\\neuron_threshold.tif']\n",
    "# raw_img = ['E:\\\\Image_Folder\\\\Raw\\\\000_B_181107_A_N1B2_4a61736f.tif']\n",
    "# mask_img = ['E:\\\\Image_Folder\\\\Mask\\\\000_B_181107_A_N1B2_4a61736f.tif']\n",
    "# experiment = \"+s_+d_-f\"\n",
    "segmentation_exp = \"+s_+d_-f\"\n",
    "ex_autofluor = False # True/False\n",
    "ex_melanocytes = True # True/False\n",
    "dim_order = (0,4,1,2,3) # define the image and mask dimension order\n",
    "output_chnl = 4\n",
    "\n",
    "patch_transform = transforms.Compose([MinMaxScalerVectorized()])\n",
    "label_transform = transforms.Compose([process_masks(exp = segmentation_exp,\n",
    "                                                    ex_autofluor=ex_autofluor,\n",
    "                                                    ex_melanocytes=ex_melanocytes,\n",
    "                                                     )])\n",
    "\n",
    "\n",
    "processed_set = WholeVolumeDataset(raw_directory = raw_img,\n",
    "                                   mask_directory= mask_img,\n",
    "                                   num_classes = output_chnl,\n",
    "                                   raw_transform = patch_transform,\n",
    "                                   label_transform = label_transform,\n",
    "                                   mask_order = dim_order,\n",
    "                                   device = device,\n",
    "                                   )\n",
    "processed_dataloader = DataLoader(processed_set, batch_size=1, shuffle= False)\n",
    "\n",
    "raw, mask = next(iter(processed_dataloader))\n",
    "mask = torch.squeeze(mask,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e5651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [03:51<00:00, 38.51s/it]\n",
      "100%|██████████| 6/6 [03:51<00:00, 38.65s/it]\n",
      "100%|██████████| 6/6 [03:48<00:00, 38.11s/it]\n",
      "100%|██████████| 6/6 [03:57<00:00, 39.58s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_results = []\n",
    "for fold_idx in range(4):\n",
    "    model_state = f\"{parent_folder}/+s_+d_-f_2D_ResUNet_{fold_idx}.pth\"\n",
    "\n",
    "    lateral_steps = config['DATASET']['lateral_steps']\n",
    "    axial_steps = config['DATASET']['axial_steps']\n",
    "    if config['MODEL']['spatial_dim'] == 3:\n",
    "        patch_size = (axial_steps, lateral_steps, lateral_steps)\n",
    "    else:\n",
    "        patch_size = (lateral_steps, lateral_steps)\n",
    "    batch_size = config['DATASET']['batch_size']\n",
    "    input_chnl = 1\n",
    "    output_chnl = 4\n",
    "    norm_type = config['MODEL']['norm']\n",
    "    dropout = 0.1\n",
    "\n",
    "    model = UNet(spatial_dims=config['MODEL']['spatial_dim'], \n",
    "                in_channels = input_chnl,\n",
    "                out_channels = output_chnl,\n",
    "                channels = config['MODEL']['channel_layers'],\n",
    "                strides=config['MODEL']['strides'],\n",
    "                num_res_units=config['MODEL']['num_res_units'],\n",
    "                norm = norm_type,\n",
    "                dropout = dropout)\n",
    "\n",
    "    checkpoint = torch.load(model_state, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "\n",
    "    # inferer = SlidingWindowInferer(roi_size=patch_size, sw_batch_size=batch_size, progress=True)\n",
    "    inferer = SliceInferer(roi_size=patch_size, sw_batch_size=batch_size, spatial_dim = 0, progress=True)\n",
    "    # predict using shifted windows\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = inferer(inputs = raw, network=model)\n",
    "    pred_results.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f60dfcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of UNet(\n",
      "  (model): Sequential(\n",
      "    (0): ResidualUnit(\n",
      "      (conv): Sequential(\n",
      "        (unit0): Convolution(\n",
      "          (conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (D): Dropout(p=0.1, inplace=False)\n",
      "            (A): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "        (unit1): Convolution(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (D): Dropout(p=0.1, inplace=False)\n",
      "            (A): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (residual): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (1): SkipConnection(\n",
      "      (submodule): Sequential(\n",
      "        (0): ResidualUnit(\n",
      "          (conv): Sequential(\n",
      "            (unit0): Convolution(\n",
      "              (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "              (adn): ADN(\n",
      "                (N): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (D): Dropout(p=0.1, inplace=False)\n",
      "                (A): PReLU(num_parameters=1)\n",
      "              )\n",
      "            )\n",
      "            (unit1): Convolution(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (adn): ADN(\n",
      "                (N): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (D): Dropout(p=0.1, inplace=False)\n",
      "                (A): PReLU(num_parameters=1)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (residual): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "        (1): SkipConnection(\n",
      "          (submodule): Sequential(\n",
      "            (0): ResidualUnit(\n",
      "              (conv): Sequential(\n",
      "                (unit0): Convolution(\n",
      "                  (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "                  (adn): ADN(\n",
      "                    (N): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (D): Dropout(p=0.1, inplace=False)\n",
      "                    (A): PReLU(num_parameters=1)\n",
      "                  )\n",
      "                )\n",
      "                (unit1): Convolution(\n",
      "                  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (adn): ADN(\n",
      "                    (N): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (D): Dropout(p=0.1, inplace=False)\n",
      "                    (A): PReLU(num_parameters=1)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (residual): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            )\n",
      "            (1): SkipConnection(\n",
      "              (submodule): Sequential(\n",
      "                (0): ResidualUnit(\n",
      "                  (conv): Sequential(\n",
      "                    (unit0): Convolution(\n",
      "                      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "                      (adn): ADN(\n",
      "                        (N): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (D): Dropout(p=0.1, inplace=False)\n",
      "                        (A): PReLU(num_parameters=1)\n",
      "                      )\n",
      "                    )\n",
      "                    (unit1): Convolution(\n",
      "                      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                      (adn): ADN(\n",
      "                        (N): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (D): Dropout(p=0.1, inplace=False)\n",
      "                        (A): PReLU(num_parameters=1)\n",
      "                      )\n",
      "                    )\n",
      "                  )\n",
      "                  (residual): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "                )\n",
      "                (1): SkipConnection(\n",
      "                  (submodule): ResidualUnit(\n",
      "                    (conv): Sequential(\n",
      "                      (unit0): Convolution(\n",
      "                        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                        (adn): ADN(\n",
      "                          (N): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                          (D): Dropout(p=0.1, inplace=False)\n",
      "                          (A): PReLU(num_parameters=1)\n",
      "                        )\n",
      "                      )\n",
      "                      (unit1): Convolution(\n",
      "                        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                        (adn): ADN(\n",
      "                          (N): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                          (D): Dropout(p=0.1, inplace=False)\n",
      "                          (A): PReLU(num_parameters=1)\n",
      "                        )\n",
      "                      )\n",
      "                    )\n",
      "                    (residual): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  )\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Convolution(\n",
      "                    (conv): ConvTranspose2d(1536, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "                    (adn): ADN(\n",
      "                      (N): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                      (D): Dropout(p=0.1, inplace=False)\n",
      "                      (A): PReLU(num_parameters=1)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): ResidualUnit(\n",
      "                    (conv): Sequential(\n",
      "                      (unit0): Convolution(\n",
      "                        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                        (adn): ADN(\n",
      "                          (N): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                          (D): Dropout(p=0.1, inplace=False)\n",
      "                          (A): PReLU(num_parameters=1)\n",
      "                        )\n",
      "                      )\n",
      "                    )\n",
      "                    (residual): Identity()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Convolution(\n",
      "                (conv): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "                (adn): ADN(\n",
      "                  (N): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (D): Dropout(p=0.1, inplace=False)\n",
      "                  (A): PReLU(num_parameters=1)\n",
      "                )\n",
      "              )\n",
      "              (1): ResidualUnit(\n",
      "                (conv): Sequential(\n",
      "                  (unit0): Convolution(\n",
      "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                    (adn): ADN(\n",
      "                      (N): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                      (D): Dropout(p=0.1, inplace=False)\n",
      "                      (A): PReLU(num_parameters=1)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (residual): Identity()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Convolution(\n",
      "            (conv): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "            (adn): ADN(\n",
      "              (N): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (D): Dropout(p=0.1, inplace=False)\n",
      "              (A): PReLU(num_parameters=1)\n",
      "            )\n",
      "          )\n",
      "          (1): ResidualUnit(\n",
      "            (conv): Sequential(\n",
      "              (unit0): Convolution(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (adn): ADN(\n",
      "                  (N): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (D): Dropout(p=0.1, inplace=False)\n",
      "                  (A): PReLU(num_parameters=1)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (residual): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Convolution(\n",
      "        (conv): ConvTranspose2d(128, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "        (adn): ADN(\n",
      "          (N): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (D): Dropout(p=0.1, inplace=False)\n",
      "          (A): PReLU(num_parameters=1)\n",
      "        )\n",
      "      )\n",
      "      (1): ResidualUnit(\n",
      "        (conv): Sequential(\n",
      "          (unit0): Convolution(\n",
      "            (conv): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (residual): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08380fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_from_categorical = np.squeeze(to_numpy(torch.argmax(pred, 1)),axis=0)\n",
    "gt_from_categorical = np.squeeze(to_numpy(torch.argmax(mask,1)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bf2dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tifffile.imwrite(\"test_inference.tif\", pred_from_categorical.astype(int))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69f32196",
   "metadata": {},
   "source": [
    "## Calculate IOU with Respect to Only Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9545ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "# preprocess the predictions and its categories\n",
    "dim_order = (0,4,1,2,3)\n",
    "pred_cat_list = []\n",
    "for fold_idx in range(4):\n",
    "    pred_cat = to_categorical_torch(torch.argmax(pred_results[fold_idx], 1), 4)\n",
    "    pred_cat = to_numpy(torch.permute(pred_cat,dim_order))\n",
    "    pred_cat_list.append(pred_cat)\n",
    "    # img_proc_pred_cat = pred_cat.clone()\n",
    "    \n",
    "    # img_proc_pred_cat = to_numpy(torch.permute(img_proc_pred_cat,dim_order))\n",
    "# mask = to_numpy(mask)\n",
    "\n",
    "# mask[mask==3] = 2 # change from filopodia to dendrites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "96600385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "dendrite_min_size = 50\n",
    "soma_min_size = 50\n",
    "\n",
    "for i in range(1,3):\n",
    "    print(i)\n",
    "    if i == 1:\n",
    "        img_proc_pred_cat[0,i,...] = morphology.remove_small_objects(img_proc_pred_cat[0,i,...], min_size=soma_min_size, connectivity=1)\n",
    "    if i == 2:\n",
    "        img_proc_pred_cat[0,i,...] = morphology.remove_small_objects(img_proc_pred_cat[0,i,...], min_size=dendrite_min_size, connectivity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3f863ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(3):\n",
    "    intersection = np.count_nonzero(pred_cat[0,i,...]*mask[0,i,...])\n",
    "    pseudo_iou = intersection/np.count_nonzero(mask[0,i,...])\n",
    "    scores.append(pseudo_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "db308232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9995756181268031, 0.6719045165722136, 0.7671754819105499]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a7cb436",
   "metadata": {},
   "source": [
    "## Try Using Morphological Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "55e5679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "28b56cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = morphology.ball(radius=1)\n",
    "dilated_image = morphology.binary_dilation(img_proc_pred_cat[0,2,...].astype(np.uint16), kernel)\n",
    "erosion_image = morphology.binary_erosion(img_proc_pred_cat[0,2,...].astype(np.uint16), kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c4b092c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the dilated and eroded images\n",
    "dilated_image = dilated_image.astype(np.uint16)\n",
    "erosion_image = erosion_image.astype(np.uint16)\n",
    "\n",
    "img_proc_pred_cat_dilated = img_proc_pred_cat.copy()\n",
    "img_proc_pred_cat_dilated[0,2,...] = dilated_image\n",
    "img_proc_pred_cat_erosion = img_proc_pred_cat.copy()\n",
    "img_proc_pred_cat_erosion[0,2,...] = erosion_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "08c2c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the gradient of the image\n",
    "\n",
    "img_proc_pred_cat_gradient = img_proc_pred_cat.copy()\n",
    "img_proc_pred_cat_gradient[0,2,...] = dilated_image - erosion_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7e784e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the closing of the image: goal is the connect the disconnected areas\n",
    "\n",
    "img_proc_pred_cat_closing = img_proc_pred_cat.copy()\n",
    "img_proc_pred_cat_closing[0,2,...] = morphology.binary_closing(img_proc_pred_cat[0,2,...].astype(np.uint16),kernel)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2776399",
   "metadata": {},
   "source": [
    "## Calculate Dice Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f1fed6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Dice Scores:  tensor([[0.7349, 0.7851, 0.0339]])\n",
      "Processed Dice Scores after getting rid of small objects tensor([[0.7422, 0.7880, 0.0339]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Pure Dice Scores: \", pure_dice_scores)\n",
    "print(\"Processed Dice Scores after getting rid of small objects\", processed_dice_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba2d56b2",
   "metadata": {},
   "source": [
    "## View Images on Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bd1743b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fungj\\anaconda3\\lib\\site-packages\\napari_tools_menu\\__init__.py:168: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86d3a073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection WRT Ground Truth:  [0.7155246436544737, 0.8013483999620169]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fungj\\anaconda3\\lib\\site-packages\\monai\\utils\\deprecate_utils.py:107: FutureWarning: <function compute_meandice at 0x000001C1E93ABDC0>: Function `compute_meandice` has been deprecated since version 1.0.0. use `compute_dice` instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Dice Scores:  tensor([0.7408, 0.7926])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Pure Prediction Fold 2' at 0x1c1ed6e7e50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_idx = 2\n",
    "from monai.metrics import compute_meandice\n",
    "\n",
    "scores = []\n",
    "for i in range(3):\n",
    "    intersection = np.count_nonzero(pred_cat_list[fold_idx][0,i,...]*to_numpy(mask[0,i,...]))\n",
    "    pseudo_iou = intersection/np.count_nonzero(mask[0,i,...])\n",
    "    scores.append(pseudo_iou)\n",
    "\n",
    "print(\"Intersection WRT Ground Truth: \", scores[1:])\n",
    "pure_dice_scores = compute_meandice(to_torch(pred_cat_list[fold_idx]), to_torch(mask), include_background=False)\n",
    "print(\"Pure Dice Scores: \", pure_dice_scores[0][0:2])\n",
    "\n",
    "pred_img = to_numpy(torch.argmax(pred_results[fold_idx], 1))\n",
    "# tmp_pred_img = np.zeros_like(pred_img)\n",
    "# tmp_pred_img[pred_img==2] = 1\n",
    "viewer.add_labels(pred_img, blending = \"additive\", name = f\"Pure Prediction Fold {fold_idx}\")\n",
    "# viewer.add_labels(pred_img, name = f\"Pure Prediction Fold {fold_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1758e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6301, 0.7262])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_dice_scores[0][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d180c872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Processed Prediction' at 0x1e45e67a6d0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_img = np.argmax(img_proc_pred_cat,1)\n",
    "viewer.add_labels(processed_img, name = \"Processed Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8e30058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Dilated Prediction [1]' at 0x1e45e67afa0>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilated_img = np.argmax(img_proc_pred_cat_dilated,1)\n",
    "viewer.add_labels(dilated_img, name = \"Dilated Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e5cc13c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Erosion Prediction [1]' at 0x1e45adcc160>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erosion_img = np.argmax(img_proc_pred_cat_erosion,1)\n",
    "viewer.add_labels(erosion_img, name = \"Erosion Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "07376cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Gradient Prediction' at 0x1e45aa5be80>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_img = np.argmax(img_proc_pred_cat_gradient,1)\n",
    "viewer.add_labels(gradient_img, name = \"Gradient Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e626e3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Closing Prediction' at 0x1e45f914eb0>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closing_img = np.argmax(img_proc_pred_cat_closing,1)\n",
    "viewer.add_labels(gradient_img, name = \"Closing Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cff7c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Ground Truth [1]' at 0x1b3a2e207f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_img = np.argmax(mask,1)\n",
    "gt_img[gt_img==3] = 0\n",
    "# tmp_gt_img = np.zeros_like(gt_img)\n",
    "# tmp_gt_img[gt_img==2] = 1\n",
    "# viewer.add_image(tmp_gt_img, colormap=\"magenta\", blending = \"additive\", name = \"Ground Truth\")\n",
    "viewer.add_labels(gt_img, name = \"Ground Truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a03a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6ca2fc8813f9b6ddd55f1976887f836d1e81bcaf3963c7a3c14df03143688c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
