{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2850c3f1",
   "metadata": {},
   "source": [
    "## Import Modules and Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61000115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T18:04:58.330150Z",
     "iopub.status.busy": "2022-07-11T18:04:58.329797Z",
     "iopub.status.idle": "2022-07-11T18:05:03.969325Z",
     "shell.execute_reply": "2022-07-11T18:05:03.968484Z",
     "shell.execute_reply.started": "2022-07-11T18:04:58.330063Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import utility libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from processing_functions import *\n",
    "\n",
    "# import deep learning libraries\n",
    "from torchvision import transforms, utils\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import trange\n",
    "\n",
    "# import processing libraries\n",
    "from patchify import unpatchify\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc02d0f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T18:05:03.970849Z",
     "iopub.status.busy": "2022-07-11T18:05:03.970628Z",
     "iopub.status.idle": "2022-07-11T18:05:03.974985Z",
     "shell.execute_reply": "2022-07-11T18:05:03.974246Z",
     "shell.execute_reply.started": "2022-07-11T18:05:03.970819Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0fd840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T18:05:03.976735Z",
     "iopub.status.busy": "2022-07-11T18:05:03.976492Z",
     "iopub.status.idle": "2022-07-11T18:05:03.980498Z",
     "shell.execute_reply": "2022-07-11T18:05:03.979822Z",
     "shell.execute_reply.started": "2022-07-11T18:05:03.976709Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # cloud server\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# macbook\n",
    "# # use_mps = torch.has_mps\n",
    "# use_mps = False\n",
    "# device = torch.device(\"mps\" if use_mps else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927fcc68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T18:05:03.981638Z",
     "iopub.status.busy": "2022-07-11T18:05:03.981417Z",
     "iopub.status.idle": "2022-07-11T18:05:03.992396Z",
     "shell.execute_reply": "2022-07-11T18:05:03.991732Z",
     "shell.execute_reply.started": "2022-07-11T18:05:03.981611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017fc17e",
   "metadata": {},
   "source": [
    "## Read TIF images into Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a70ff2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T18:05:03.993581Z",
     "iopub.status.busy": "2022-07-11T18:05:03.993360Z",
     "iopub.status.idle": "2022-07-11T18:05:04.226394Z",
     "shell.execute_reply": "2022-07-11T18:05:04.225584Z",
     "shell.execute_reply.started": "2022-07-11T18:05:03.993554Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import tifffile\n",
    "import glob\n",
    "\n",
    "# Cloud Server\n",
    "raw_path = \"/home/jovyan/workspace/Images/Raw/*.tif\"\n",
    "mask_path = \"/home/jovyan/workspace/Images/Mask/*.tif\"\n",
    "\n",
    "# # Jason's Desktop\n",
    "# raw_path = \"H:\\My Drive\\Raw\\*.tif\"\n",
    "# mask_path = \"H:\\My Drive\\Mask\\*.tif\"\n",
    "\n",
    "# # Jason's Macbook\n",
    "# raw_path = \"/Users/jasonfung/haaslabdataimages@gmail.com - Google Drive/My Drive/Raw/*.tif\"\n",
    "# mask_path = \"/Users/jasonfung/haaslabdataimages@gmail.com - Google Drive/My Drive/Mask/*.tif\"\n",
    "\n",
    "raw_filename_list = glob.glob(raw_path) \n",
    "mask_filename_list = glob.glob(mask_path)\n",
    "\n",
    "# Pre Shuffle\n",
    "raw_filename_list.sort()\n",
    "mask_filename_list.sort()\n",
    "\n",
    "# Shuffle the filename list\n",
    "from sklearn.utils import shuffle\n",
    "raw_filename_list, mask_filename_list = shuffle(raw_filename_list, mask_filename_list, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c6d5c23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T18:05:04.278013Z",
     "iopub.status.busy": "2022-07-11T18:05:04.277707Z",
     "iopub.status.idle": "2022-07-11T18:05:04.284051Z",
     "shell.execute_reply": "2022-07-11T18:05:04.282962Z",
     "shell.execute_reply.started": "2022-07-11T18:05:04.277983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/workspace/Images/Raw/000_ML_20190604_B_52616a61.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/00_ML_20180614_N1_50616967.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/000_B_181107_A_N1B2_4a61736f.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/00_ML_20180614_N5_52616a61.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/000_ML_20180621_A_52616a61.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/000_ML_20190604_A_52616a61.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/000_D_180907_A_N1B3_52616a61.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/000_D_180906_A_N1C1_53696168.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/060_B_181031_A_N1B3_52616a61.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/000_ML_20180613_N4_4a61736f.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/000_ML_20180622_N2_50616967.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/00_GFPC_20180615_N1_50616967.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/000_GFP_181027_52616a61.tif',\n",
       " '/home/jovyan/workspace/Images/Raw/000_ML_20180622_N1_53696168.tif']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6fb076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T18:05:05.017119Z",
     "iopub.status.busy": "2022-07-11T18:05:05.016812Z",
     "iopub.status.idle": "2022-07-11T18:05:05.022844Z",
     "shell.execute_reply": "2022-07-11T18:05:05.021905Z",
     "shell.execute_reply.started": "2022-07-11T18:05:05.017088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_filename_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720452c",
   "metadata": {},
   "source": [
    "## Processing Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d5855d",
   "metadata": {},
   "source": [
    "## Patching and Reconstruction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3092f61a",
   "metadata": {},
   "source": [
    "Input of an image is (# z stacks, # x pixels, # y pixels). Then it is split into sub volumes of size (z patch size, x patch size, y patch size) where each subvolume is (voxelized), meaning it has a coordinate relative to the original image. This ends up becoming a (z location, x location, y location, z patch size, x patch size, y patch size).\n",
    "\n",
    "If the image has a depth that cannot be evenly split by 2^n depth patch size where n is an integer, the function patch_images() will return an \"upper half\" and a \"lower half\" of the image. For example, given an image size of (77,512,512) and a z patch size of 16, x patch size of 32, and y patch of 32, the image cannot be evenly split into 16ths, since 77 % 16 = 4 remainder 13. Therefore, starting from the top of the stack to slice 64: the upper half becomes (64, 512, 512). Contrastly, starting from the bottom of the stack at slice 77 to slice 61, the lower half becomes (16, 512, 512). The two split volumes will become merged in the end.\n",
    "\n",
    "To prepare for training, the coordinated subvolumes are reshaped into \"batch form\". From the previous example with the upper half (64, 512, 512) split and coordinated into a 6D array (4, 16, 16, 16, 32, 32) -> (4 * 16 * 16, 16, 32, 32).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e6739b",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f088ef2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T18:05:08.284443Z",
     "iopub.status.busy": "2022-07-11T18:05:08.284135Z",
     "iopub.status.idle": "2022-07-11T18:05:08.292680Z",
     "shell.execute_reply": "2022-07-11T18:05:08.291737Z",
     "shell.execute_reply.started": "2022-07-11T18:05:08.284413Z"
    }
   },
   "outputs": [],
   "source": [
    "def iou(outputs: torch.Tensor, labels: torch.Tensor, smooth=1e-6):\n",
    "    # multiclass IOU: intersection is where classes agree; union is any non-null class\n",
    "    \n",
    "    intersection = (outputs == labels).float().sum((-1, -2, -3)) # Will be zero if Truth=0 or Prediction=0\n",
    "    union = ((outputs != 0) | (labels != 0)).float().sum((-1, -2, -3)) # Will be zero if both are 0\n",
    "    \n",
    "    iou = (intersection + smooth) / (union + smooth) # We smooth our devision to avoid 0/0\n",
    "    \n",
    "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
    "    return thresholded.mean()\n",
    "\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, weight=None, num_classes = 2, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        # flatten label and prediction tensors\n",
    "        inputs = torch.flatten(inputs)\n",
    "        targets = torch.flatten(targets)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2 * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)        \n",
    "        return dice\n",
    "    \n",
    "# class FocalLoss(torch.nn.modules.loss._WeightedLoss):\n",
    "#     \"\"\"\n",
    "#     From https://github.com/ZFTurbo/segmentation_models_3D/blob/cc9f4fdd22387cc1556c77a85c7bea43e541ef1d/segmentation_models_3D/base/functional.py#L259\n",
    "#     as oppose to https://github.com/gokulprasadthekkel/pytorch-multi-class-focal-loss/blob/master/focal_loss.py#L11\n",
    "#     \"\"\"\n",
    "#     def __init__(self, weight=None, gamma=2, alpha=0.25, reduction='mean'):\n",
    "#         super(FocalLoss, self).__init__(weight, reduction=reduction)\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha\n",
    "#         self.weight = weight # weight parameter will act as the alpha parameter to balance class weights\n",
    "\n",
    "#     def forward(self, pr, gt, smooth=1e-6):\n",
    "#         # clip to prevent NaN's and Inf's\n",
    "#         pr = torch.clamp(pr, smooth, 1 - smooth)\n",
    "        \n",
    "#         focal_loss = -1 * gt * torch.log(pr) * (self.alpha * (1 - pr) ** self.gamma)\n",
    "        \n",
    "#         # ce_loss = torch.nn.functional.cross_entropy(input, target, reduction=self.reduction, weight=self.weight)\n",
    "#         # pt = torch.exp(-ce_loss)\n",
    "#         # focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        \n",
    "#         return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e2512",
   "metadata": {},
   "source": [
    "## Split Training and Testing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "939f5aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T18:05:34.354730Z",
     "iopub.status.busy": "2022-07-11T18:05:34.354420Z",
     "iopub.status.idle": "2022-07-11T18:05:34.363962Z",
     "shell.execute_reply": "2022-07-11T18:05:34.363154Z",
     "shell.execute_reply.started": "2022-07-11T18:05:34.354699Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# define patching parameters\n",
    "lateral_steps = 64\n",
    "axial_steps = 16\n",
    "patch_size = (axial_steps, lateral_steps, lateral_steps)\n",
    "split_size = 0.8\n",
    "dim_order = (0,4,1,2,3) # define the image and mask dimension order\n",
    "\n",
    "patch_transform = transforms.Compose([\n",
    "#                                       new_shape(new_xy = (600,960)),\n",
    "                                      MinMaxScalerVectorized(),\n",
    "                                      patch_imgs(xy_step = lateral_steps, z_step = axial_steps, patch_size = patch_size, is_mask = False)])\n",
    "\n",
    "# define transforms for labeled masks\n",
    "label_transforms = transforms.Compose([\n",
    "#                                        new_shape(new_xy = (600,960)),\n",
    "                                       process_masks(int_class = 3),\n",
    "                                       patch_imgs(xy_step = lateral_steps, z_step = axial_steps, patch_size = patch_size, is_mask = True)])\n",
    "\n",
    "\n",
    "raw_training_list, mask_training_list = raw_filename_list[:int(split_size*len(raw_filename_list))], mask_filename_list[:int(split_size*len(mask_filename_list))]\n",
    "raw_testing_list, mask_testing_list = raw_filename_list[int(split_size*len(raw_filename_list)):], mask_filename_list[int(split_size*len(mask_filename_list)):]\n",
    "print(len(raw_training_list))\n",
    "print(len(raw_testing_list))\n",
    "\n",
    "training_data = MyImageDataset(raw_training_list,\n",
    "                               mask_training_list,\n",
    "                               transform = patch_transform,\n",
    "                               label_transform = label_transforms,\n",
    "                               device = device,\n",
    "                               img_order = dim_order,\n",
    "                               mask_order = dim_order,\n",
    "                               num_classes = 4,\n",
    "                               train=True)\n",
    "\n",
    "testing_data = MyImageDataset(raw_testing_list,\n",
    "                              mask_testing_list,\n",
    "                              transform = patch_transform,\n",
    "                              label_transform = label_transforms,\n",
    "                              device = device,\n",
    "                              img_order = dim_order,\n",
    "                              mask_order = dim_order,\n",
    "                              num_classes = 4,\n",
    "                              train=False)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "training_dataloader = DataLoader(training_data, batch_size = 1, shuffle = True)\n",
    "testing_dataloader = DataLoader(testing_data, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ed6711",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa0e0b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T18:05:38.011137Z",
     "iopub.status.busy": "2022-07-11T18:05:38.010805Z",
     "iopub.status.idle": "2022-07-11T18:05:38.837498Z",
     "shell.execute_reply": "2022-07-11T18:05:38.836548Z",
     "shell.execute_reply.started": "2022-07-11T18:05:38.011107Z"
    }
   },
   "outputs": [],
   "source": [
    "# from monai.losses import DiceLoss\n",
    "from monai.losses import FocalLoss, DiceFocalLoss, DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import BasicUNet, UNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3fe373",
   "metadata": {},
   "source": [
    "## Model and Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53aaa1dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T18:05:39.333426Z",
     "iopub.status.busy": "2022-07-11T18:05:39.333086Z",
     "iopub.status.idle": "2022-07-11T18:05:43.833576Z",
     "shell.execute_reply": "2022-07-11T18:05:43.832767Z",
     "shell.execute_reply.started": "2022-07-11T18:05:39.333394Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up loss and optimizer\n",
    "max_epochs = 250\n",
    "dropout = 0.10\n",
    "learning_rate = 5e-5\n",
    "decay = 1e-5\n",
    "input_chnl = 1\n",
    "output_chnl = 4\n",
    "\n",
    "model = UNet(spatial_dims=3, \n",
    "             in_channels = input_chnl,\n",
    "             out_channels = output_chnl,\n",
    "             channels = (16, 32, 64, 128, 256),\n",
    "             strides=(2, 2, 2, 2),\n",
    "             num_res_units=2,\n",
    "             norm = \"batch\",\n",
    "             dropout = dropout)\n",
    "model = model.to(device)\n",
    "\n",
    "# loss_function = FocalLoss()\n",
    "loss_function = DiceCELoss()\n",
    "dice = DiceMetric()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "# Instantiate Dice metric\n",
    "dice = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans = True)\n",
    "discretize = Compose([Activations(softmax = True), \n",
    "                      AsDiscrete(logit_thresh=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2c2b09b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T18:06:03.033774Z",
     "iopub.status.busy": "2022-07-11T18:06:03.033443Z",
     "iopub.status.idle": "2022-07-11T18:06:03.039547Z",
     "shell.execute_reply": "2022-07-11T18:06:03.038813Z",
     "shell.execute_reply.started": "2022-07-11T18:06:03.033743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4531009\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9078602",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cdf71d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T02:25:28.827739Z",
     "iopub.status.busy": "2022-07-09T02:25:28.827527Z",
     "iopub.status.idle": "2022-07-09T02:25:28.832017Z",
     "shell.execute_reply": "2022-07-09T02:25:28.831324Z",
     "shell.execute_reply.started": "2022-07-09T02:25:28.827711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Augmentation Function parameters\n",
    "degree = (25, 5, 5)\n",
    "# translate = (10,10,10)\n",
    "transform_rotate = torchio.RandomAffine(degrees=degree, \n",
    "#                                         translation=translate, \n",
    "                                        image_interpolation=\"bspline\")\n",
    "transform_flip = torchio.RandomFlip(axes=('ap',))\n",
    "all_transform = torchio.Compose([transform_rotate,\n",
    "                                 transform_flip])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019c1bec",
   "metadata": {},
   "source": [
    "## Compose Dice Metric and Discretize Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a29c3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T02:25:28.833095Z",
     "iopub.status.busy": "2022-07-09T02:25:28.832872Z",
     "iopub.status.idle": "2022-07-09T02:25:28.837193Z",
     "shell.execute_reply": "2022-07-09T02:25:28.836454Z",
     "shell.execute_reply.started": "2022-07-09T02:25:28.833066Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize metric lists to store Dice metrics\n",
    "mean_dice = []\n",
    "dice_soma = []\n",
    "dice_dendrite = []\n",
    "dice_filopodias = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22632bd",
   "metadata": {},
   "source": [
    "## Define Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bb7f3d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T02:25:28.838271Z",
     "iopub.status.busy": "2022-07-09T02:25:28.838071Z",
     "iopub.status.idle": "2022-07-09T02:25:28.863191Z",
     "shell.execute_reply": "2022-07-09T02:25:28.862543Z",
     "shell.execute_reply.started": "2022-07-09T02:25:28.838245Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(batch_size, model, patch_size, augment = True, shuffle = True):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0\n",
    "    count_loss = 0\n",
    "    # Instantiate the dice sum for each class\n",
    "    dice_mean = dice_background = dice_soma = dice_dendrite = dice_filopodias = 0.0\n",
    "    dice_count = 0\n",
    "    img_num = 0\n",
    "    \n",
    "    for upper_img, upper_shape, lower_img, lower_shape, full_mask, upper_mask, lower_mask in training_dataloader:\n",
    "        \n",
    "        img_num += 1\n",
    "        print(\"Training Image: \", img_num)\n",
    "        # Empty list to place subvolumes in\n",
    "        tmp_upper_dict = {}\n",
    "        tmp_lower_dict = {}    \n",
    "        \n",
    "        if shuffle == True:\n",
    "            # shuffle the batches\n",
    "            upper_key_list = list(range(len(upper_img)))\n",
    "            random.shuffle(upper_key_list)\n",
    "            \n",
    "            # check if lower img exists, otherwise perform shuffling\n",
    "            if lower_img == None:\n",
    "                pass\n",
    "            else:\n",
    "                lower_key_list = list(range(len(lower_img)))\n",
    "                random.shuffle(upper_key_list)\n",
    "        else:\n",
    "            upper_key_list = list(range(len(upper_img)))\n",
    "            lower_key_list = list(range(len(lower_img)))\n",
    "        \n",
    "        \n",
    "        # Only train on evenly split images\n",
    "        if lower_img == None:\n",
    "            num_subvolumes = len(upper_img)\n",
    "            for bindex in trange(0, num_subvolumes, batch_size):\n",
    "                if bindex + batch_size > num_subvolumes:\n",
    "                    # if the bindex surpasses the number of number of sub volumes\n",
    "                    batch_keys = upper_key_list[bindex:num_sub_volumes]\n",
    "                else:\n",
    "                    batch_keys = upper_key_list[bindex:bindex+batch_size]\n",
    "                \n",
    "                sub_imgs = torch.squeeze(torch.stack([upper_img.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "                sub_masks = torch.squeeze(torch.stack([upper_mask.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "               \n",
    "                optimizer.zero_grad()\n",
    "                output = model(sub_imgs)\n",
    "                probabilities = torch.softmax(ouput, 1)\n",
    "                \n",
    "                # discretize probability values \n",
    "                prediction = torch.argmax(probabilities, 1)\n",
    "                tmp_upper_dict.update(dict(zip(batch_keys,prediction)))\n",
    "                \n",
    "                # calculate the loss for the current batch, save the loss per epoch to calculate the average running loss\n",
    "                current_loss = loss_function(probabilities, sub_masks) # + dice_loss(predictions, patch_gt)\n",
    "                \n",
    "                current_loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += current_loss.item()\n",
    "                dice_count += 1\n",
    "            \n",
    "            # lower list does not exist\n",
    "            tmp_lower_list = None\n",
    "                \n",
    "        # train on both \n",
    "        else:\n",
    "            print(\"Training Upper Half of Image\")\n",
    "            num_upper_subvolumes = len(upper_img)\n",
    "            if augment:\n",
    "                print(\"Augmenting Images\")\n",
    "                upper_indexes = get_index_nonempty_cubes(upper_mask)\n",
    "\n",
    "                for bindex in trange(0, len(upper_indexes), batch_size):\n",
    "                    # for augmentation\n",
    "                    if bindex + batch_size > len(upper_indexes):\n",
    "                        upper_batch = upper_indexes[bindex:len(upper_indexes)]\n",
    "                    else:\n",
    "                        upper_batch = upper_indexes[bindex:bindex+batch_size]\n",
    "                        \n",
    "                    sub_imgs, sub_masks = augmentation(all_transform, upper_img, upper_mask, upper_batch)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(sub_imgs)\n",
    "                    probabilities = torch.softmax(output, 1)\n",
    "                    prediction = torch.argmax(probabilities, 1)\n",
    "                    \n",
    "                    current_loss = loss_function(probabilities, sub_masks)\n",
    "                    current_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss += current_loss.item()\n",
    "                    count_loss += 1\n",
    "            \n",
    "            \n",
    "            for bindex in trange(0, num_upper_subvolumes, batch_size):\n",
    "                if bindex + batch_size > num_upper_subvolumes:\n",
    "                    # if the bindex surpasses the number of number of sub volumes\n",
    "                    batch_keys = upper_key_list[bindex:num_upper_subvolumes]\n",
    "                else:\n",
    "                    batch_keys = upper_key_list[bindex:bindex+batch_size]\n",
    "                \n",
    "                sub_imgs = torch.squeeze(torch.stack([upper_img.get(key) for key in batch_keys], dim=1), dim = 0) \n",
    "                sub_masks = torch.squeeze(torch.stack([upper_mask.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = model(sub_imgs) # predict the batches\n",
    "                probabilities = torch.softmax(output, 1) \n",
    "                prediction = torch.argmax(probabilities,1)\n",
    "                \n",
    "                # update the upper img dictionary\n",
    "                tmp_upper_dict.update(dict(zip(batch_keys,prediction)))\n",
    "                \n",
    "                current_loss = loss_function(probabilities, sub_masks) # + dice_loss(predictions, patch_gt)\n",
    "                \n",
    "                current_loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += current_loss.item()\n",
    "                count_loss += 1\n",
    "            \n",
    "            print(\"Training Lower Half of Image\")\n",
    "            num_lower_subvolumes = len(lower_img)\n",
    "            if augment:\n",
    "                print(\"Augmenting Lower Half Images\")\n",
    "                \n",
    "                lower_indexes = get_index_nonempty_cubes(lower_mask)\n",
    "                \n",
    "                for bindex in trange(0, len(lower_indexes), batch_size):\n",
    "                    # for augmentation\n",
    "                    if bindex + batch_size > len(lower_indexes):\n",
    "                        lower_batch = lower_indexes[bindex:len(lower_indexes)]\n",
    "                    else:\n",
    "                        lower_batch = lower_indexes[bindex:bindex+batch_size]\n",
    "                        \n",
    "                    sub_imgs, sub_masks = augmentation(all_transform, upper_img, upper_mask, upper_batch)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(sub_imgs)\n",
    "                    probabilities = torch.softmax(output, 1)\n",
    "                    prediction = torch.argmax(probabilities, 1)\n",
    "                    \n",
    "                    current_loss = loss_function(probabilities, sub_masks)\n",
    "                    current_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss += current_loss.item()\n",
    "                    count_loss += 1\n",
    "                    \n",
    "            print(\"Non Augmented Image\")\n",
    "            for bindex in trange(0, num_lower_subvolumes, batch_size):\n",
    "                if bindex + batch_size > num_lower_subvolumes:\n",
    "                    # if the bindex surpasses the number of number of sub volumes\n",
    "                    batch_keys = lower_key_list[bindex:num_lower_subvolumes]\n",
    "                else:\n",
    "                    batch_keys = lower_key_list[bindex:bindex+batch_size]\n",
    "                \n",
    "                sub_imgs = torch.squeeze(torch.stack([lower_img.get(key) for key in batch_keys], dim=1), dim = 0) \n",
    "                sub_masks = torch.squeeze(torch.stack([lower_mask.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = model(sub_imgs)\n",
    "                probabilities = torch.softmax(output, 1)\n",
    "                prediction = torch.argmax(probabilities,1)\n",
    "                \n",
    "                # update the lower dictionary\n",
    "                tmp_lower_dict.update(dict(zip(batch_keys,prediction)))\n",
    "\n",
    "                current_loss = loss_function(probabilities, sub_masks) # + dice_loss(predictions, patch_gt)\n",
    "                \n",
    "                current_loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += current_loss.item()\n",
    "                count_loss += 1\n",
    "\n",
    "        # neuron reconstruction to calculate the dice metric.\n",
    "        orig_shape = full_mask.shape[1:-1]\n",
    "        reconstructed_mask_order = (3,0,1,2)\n",
    "        \n",
    "        upper_values = torch.stack([tmp_upper_dict[key] for key in list(range(len(tmp_upper_dict)))])\n",
    "        lower_values = torch.stack([tmp_lower_dict[key] for key in list(range(len(tmp_lower_dict)))])\n",
    "        \n",
    "        \n",
    "        reconstructed = reconstruct_training_masks(upper_values, lower_values, upper_shape, \n",
    "                                                   lower_shape, patch_size, orig_shape) # returns (z,y,x)\n",
    "        reconstructed = to_categorical_torch(reconstructed, num_classes = 4) # returns (z,y,x,c)\n",
    "        reconstructed = torch.permute(reconstructed, reconstructed_mask_order)\n",
    "        reconstructed = torch.unsqueeze(reconstructed, 0) # make reconstructed image into (Batch,c,z,y,x)\n",
    "        \n",
    "        gt_mask = torch.permute(full_mask, dim_order).cpu() # roll axis of grount truth mask into (batch,c,z,y,x)\n",
    "        \n",
    "        # compute the dice score for each class\n",
    "        scores = dice(reconstructed, gt_mask)\n",
    "        scores = scores[0]\n",
    "        dice_mean += scores.mean()\n",
    "        dice_background += scores[0]\n",
    "        dice_soma += scores[1]\n",
    "        dice_dendrite += scores[2]\n",
    "        dice_filopodias += scores[3]\n",
    "        \n",
    "        dice_count += 1 \n",
    "        \n",
    "#         print(f'Training Dice: Mean = {dice_mean/dice_count}, Background = {dice_background/dice_count}, Soma = {dice_soma/dice_count}, Dendrite = {dice_dendrite/dice_count}, Filopodias = {dice_filopodias/dice_count}')\n",
    "#         print(f'Training loss: {running_loss / count_loss}')\n",
    "#         # print(f'Training Dice: {running_dice / count}')\n",
    "#         writer.add_scalar('Training batch loss', running_loss / count_loss)\n",
    "#         writer.flush()\n",
    "    \n",
    "#     scheduler.step()\n",
    "    running_dice = [dice_background/dice_count, dice_soma/dice_count, dice_dendrite/dice_count, dice_filopodias/dice_count]\n",
    "        \n",
    "    return running_dice, running_loss / count_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88c0cbf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T02:25:28.864372Z",
     "iopub.status.busy": "2022-07-09T02:25:28.864130Z",
     "iopub.status.idle": "2022-07-09T02:25:28.882056Z",
     "shell.execute_reply": "2022-07-09T02:25:28.881318Z",
     "shell.execute_reply.started": "2022-07-09T02:25:28.864347Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(batch_size, model, patch_size, shuffle = False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0\n",
    "        count_loss = 0\n",
    "        # Instantiate the dice sum for each class\n",
    "        dice_mean = dice_background = dice_soma = dice_dendrite = dice_filopodias = 0.0\n",
    "        dice_count = 0\n",
    "        img_num = 0\n",
    "\n",
    "        for upper_img, upper_shape, lower_img, lower_shape, full_mask, upper_mask, lower_mask in testing_dataloader:\n",
    "            img_num += 1\n",
    "            print(\"Training Image: \", img_num)\n",
    "            # Empty list to place subvolumes in\n",
    "            tmp_upper_dict = {}\n",
    "            tmp_lower_dict = {}    \n",
    "\n",
    "            if shuffle == True:\n",
    "                # shuffle the batches\n",
    "                upper_key_list = list(range(len(upper_img)))\n",
    "                random.shuffle(upper_key_list)\n",
    "\n",
    "                # check if lower img exists, otherwise perform shuffling\n",
    "                if lower_img == None:\n",
    "                    pass\n",
    "                else:\n",
    "                    lower_key_list = list(range(len(lower_img)))\n",
    "                    random.shuffle(upper_key_list)\n",
    "            else:\n",
    "                upper_key_list = list(range(len(upper_img)))\n",
    "                lower_key_list = list(range(len(lower_img)))\n",
    "\n",
    "\n",
    "            # Only train on evenly split images\n",
    "            if lower_img == None:\n",
    "                num_subvolumes = len(upper_img)\n",
    "                for bindex in trange(0, num_subvolumes, batch_size):\n",
    "                    if bindex + batch_size > num_subvolumes:\n",
    "                        # if the bindex surpasses the number of number of sub volumes\n",
    "                        batch_keys = upper_key_list[bindex:num_sub_volumes]\n",
    "                    else:\n",
    "                        batch_keys = upper_key_list[bindex:bindex+batch_size]\n",
    "                    \n",
    "                    sub_imgs = torch.squeeze(torch.stack([upper_img.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "                    sub_masks = torch.squeeze(torch.stack([upper_mask.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(sub_imgs)\n",
    "                    probabilities = torch.softmax(ouput, 1)\n",
    "\n",
    "                    # discretize probability values \n",
    "                    prediction = torch.argmax(probabilities, 1)\n",
    "                    tmp_upper_dict.update(dict(zip(batch_keys,sub_prediction)))\n",
    "\n",
    "                    # calculate the loss for the current batch, save the loss per epoch to calculate the average running loss\n",
    "                    current_loss = loss_function(probabilities, sub_masks) # + dice_loss(predictions, patch_gt)\n",
    "                    running_loss += current_loss.item()\n",
    "                    dice_count += 1\n",
    "\n",
    "                # lower list does not exist\n",
    "                tmp_lower_list = None\n",
    "\n",
    "            # train on both \n",
    "            else:\n",
    "                print(\"Validating Upper Half of Image\")\n",
    "                num_subvolumes = len(upper_img)\n",
    "                for bindex in trange(0, num_subvolumes, batch_size):\n",
    "                    if bindex + batch_size > num_subvolumes:\n",
    "                        # if the bindex surpasses the number of number of sub volumes\n",
    "                        batch_keys = upper_key_list[bindex:num_sub_volumes]\n",
    "                    else:\n",
    "                        batch_keys = upper_key_list[bindex:bindex+batch_size]\n",
    "                    \n",
    "                    sub_imgs = torch.squeeze(torch.stack([upper_img.get(key) for key in batch_keys], dim=1), dim = 0) \n",
    "                    sub_masks = torch.squeeze(torch.stack([upper_mask.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(sub_imgs) # predict the batches\n",
    "                    probabilities = torch.softmax(output, 1) \n",
    "                    prediction = torch.argmax(probabilities,1)\n",
    "\n",
    "                    # update the upper img dictionary\n",
    "                    tmp_upper_dict.update(dict(zip(batch_keys,prediction)))\n",
    "\n",
    "                    current_loss = loss_function(probabilities, sub_masks) # + dice_loss(predictions, patch_gt)\n",
    "                    running_loss += current_loss.item()\n",
    "                    count_loss += 1\n",
    "\n",
    "                print(\"Validating Lower Half of Image\")\n",
    "                num_subvolumes = len(lower_img)\n",
    "                for bindex in trange(0, num_subvolumes, batch_size):\n",
    "                    if bindex + batch_size > num_subvolumes:\n",
    "                        # if the bindex surpasses the number of number of sub volumes\n",
    "                        batch_keys = lower_key_list[bindex:num_sub_volumes]\n",
    "                    else:\n",
    "                        batch_keys = lower_key_list[bindex:bindex+batch_size]\n",
    "                    \n",
    "                    sub_imgs = torch.squeeze(torch.stack([lower_img.get(key) for key in batch_keys], dim=1), dim = 0) \n",
    "                    sub_masks = torch.squeeze(torch.stack([lower_mask.get(key) for key in batch_keys], dim=1), dim = 0)\n",
    "\n",
    "                    output = model(sub_imgs)\n",
    "                    probabilities = torch.softmax(output, 1)\n",
    "                    prediction = torch.argmax(probabilities,1)\n",
    "\n",
    "                    # update the lower dictionary\n",
    "                    tmp_lower_dict.update(dict(zip(batch_keys,prediction)))\n",
    "\n",
    "                    current_loss = loss_function(probabilities, sub_masks) # + dice_loss(predictions, patch_gt)\n",
    "                    running_loss += current_loss.item()\n",
    "                    count_loss += 1\n",
    "\n",
    "                # return tmp_upper_list, tmp_lower_list, running_loss / count\n",
    "        \n",
    "            # neuron reconstruction to calculate the dice metric.\n",
    "            orig_shape = full_mask.shape[1:-1]\n",
    "            reconstructed_mask_order = (3,0,1,2)\n",
    "\n",
    "\n",
    "            upper_values = torch.stack([tmp_upper_dict[key] for key in list(range(len(tmp_upper_dict)))])\n",
    "            lower_values = torch.stack([tmp_lower_dict[key] for key in list(range(len(tmp_lower_dict)))])\n",
    "\n",
    "\n",
    "            reconstructed = reconstruct_training_masks(upper_values, lower_values, upper_shape, \n",
    "                                                       lower_shape, patch_size, orig_shape) # returns (z,y,x)\n",
    "            reconstructed = to_categorical_torch(reconstructed, num_classes = 4) # returns (z,y,x,c)\n",
    "            reconstructed = torch.permute(reconstructed, reconstructed_mask_order)\n",
    "            reconstructed = torch.unsqueeze(reconstructed, 0) # make reconstructed image into (Batch,c,z,y,x)\n",
    "\n",
    "            gt_mask = torch.permute(full_mask, dim_order).cpu() # roll axis of grount truth mask into (batch,c,z,y,x)\n",
    "\n",
    "            # compute the dice score for each class\n",
    "            scores = dice(reconstructed, gt_mask)\n",
    "            scores = scores[0]\n",
    "            dice_mean += scores.mean()\n",
    "            dice_background += scores[0]\n",
    "            dice_soma += scores[1]\n",
    "            dice_dendrite += scores[2]\n",
    "            dice_filopodias += scores[3]\n",
    "\n",
    "            dice_count += 1 \n",
    "\n",
    "    #         print(f'Training Dice: Mean = {dice_mean/dice_count}, Background = {dice_background/dice_count}, Soma = {dice_soma/dice_count}, Dendrite = {dice_dendrite/dice_count}, Filopodias = {dice_filopodias/dice_count}')\n",
    "    #         print(f'Training loss: {running_loss / count_loss}')\n",
    "    #         # print(f'Training Dice: {running_dice / count}')\n",
    "    #         writer.add_scalar('Training batch loss', running_loss / count_loss)\n",
    "    #         writer.flush()\n",
    "\n",
    "#         scheduler.step()\n",
    "        \n",
    "        running_dice = [dice_background/dice_count, dice_soma/dice_count, dice_dendrite/dice_count, dice_filopodias/dice_count]\n",
    "        \n",
    "        return running_dice, running_loss / count_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c930c1f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T02:25:28.883184Z",
     "iopub.status.busy": "2022-07-09T02:25:28.882982Z",
     "iopub.status.idle": "2022-07-09T02:25:37.415229Z",
     "shell.execute_reply": "2022-07-09T02:25:37.413909Z",
     "shell.execute_reply.started": "2022-07-09T02:25:28.883159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0: \n",
      "Training Image:  1\n",
      "Training Upper Half of Image\n",
      "Augmenting Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 15.78 GiB total capacity; 13.92 GiB already allocated; 264.75 MiB free; 14.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c88fb989b84c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' Epoch {epoch}: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrain_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mval_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-ec32b307c772>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(batch_size, model, patch_size, augment, shuffle)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/monai/networks/nets/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/monai/networks/layers/simplelayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/monai/networks/layers/simplelayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/monai/networks/layers/simplelayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/monai/networks/blocks/convolutions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# create the additive residual from x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# apply x to sequence of operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mres\u001b[0m  \u001b[0;31m# add the residual to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 15.78 GiB total capacity; 13.92 GiB already allocated; 264.75 MiB free; 14.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# # macbook log directory\n",
    "# log_directory = '/Users/jasonfung/Documents/Masters Project/Results/runs/unet/trainer_{}'\n",
    "\n",
    "# windows log directory\n",
    "# log_directory = \"\\\\Users\\\\Fungj\\\\Documents\\\\Results_{}\"\n",
    "\n",
    "# # cloud log and model directory\n",
    "log_directory = \"/home/jovyan/workspace/results/logs/resunet/trainer_{}\" \n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter(log_directory.format(timestamp))\n",
    "\n",
    "output_dir = '/home/jovyan/workspace/results/models/resunet/'\n",
    "\n",
    "\n",
    "best_val_loss = np.inf\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f' Epoch {epoch}: ')\n",
    "    train_dice, train_loss = train(batch_size, model, patch_size)\n",
    "    val_dice, val_loss = validate(batch_size, model, patch_size)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}: Loss train {train_loss}; Dice train {train_dice}; validation {val_loss}; validation IOU {val_dice}')\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                       {'Training' : train_loss, 'Validation' : val_loss}, epoch)\n",
    "    writer.add_scalars('Training vs. Validation Mean Dice ',\n",
    "                       {'Training Mean Dice' : np.mean(train_dice), 'Validation Mean Dice' : np.mean(val_dice)}, epoch)\n",
    "    writer.add_scalars('Training vs. Validation Soma Dice ',\n",
    "                       {'Training Soma Dice' : train_dice[1], 'Validation Soma Dice' : val_dice[1]}, epoch)\n",
    "    writer.add_scalars('Training vs. Validation Dendrite Dice ',\n",
    "                       {'Training Dendrite Dice' : train_dice[2], 'Validation Dendrite Dice' : val_dice[2]}, epoch)\n",
    "    writer.add_scalars('Training vs. Validation Filopodias Dice ',\n",
    "                       {'Training Filopodias Dice' : train_dice[3], 'Validation Filopodias Dice' : val_dice[3]}, epoch)\n",
    "    writer.flush()\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        model_path = output_dir + f'model_{timestamp}_{epoch}'\n",
    "        torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
